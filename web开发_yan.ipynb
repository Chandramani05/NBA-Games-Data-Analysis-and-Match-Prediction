{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chandramani05/NBA-Games-Data-Analysis-and-Match-Prediction/blob/main/web%E5%BC%80%E5%8F%91_yan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "from datetime import date\n",
        "from datetime import timedelta\n",
        "import pytz\n",
        "from dateutil import parser\n",
        "import re\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import * \n",
        "import pickle\n",
        "from google.colab import drive\n",
        "from keras.models import load_model\n",
        "drive.mount('/content/drive')\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "from numpy import inf\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "yAgTQNTCCs_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26db128a-66d3-42a1-a909-ea60e284a377"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "2Iuu0krPSLL8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load The Trained Model"
      ],
      "metadata": {
        "id": "GZyszXcURVq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/Machine Learning NBA /NBA-Games-Data-Analysis-and-Match-Prediction/Models/ANN')"
      ],
      "metadata": {
        "id": "3RmF-JDN5oLf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Helper Function"
      ],
      "metadata": {
        "id": "gj2GsKw4RZfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def make_request(endpoint, params=None, record_path=None, verbose=False):\n",
        "    root = \"https://www.balldontlie.io/api/v1/\"\n",
        "    response = requests.get(root + endpoint, params=params)\n",
        "    if response.status_code != 200:\n",
        "        return response\n",
        "    if verbose: \n",
        "        print(\"Success!\")  \n",
        "    df = pd.json_normalize(response.json(), record_path=record_path)\n",
        "   \n",
        "    # If the request ends up being a multi page request, get all the pages\n",
        "    # and then complile the results into one dataframe\n",
        "    n_pages = response.json()[\"meta\"][\"total_pages\"] \n",
        "    if n_pages > 1:\n",
        "        for page_num in range(2, n_pages + 1):\n",
        "            # Make sure not to exceed the 60 request per second limit\n",
        "            time.sleep(1)\n",
        "        # The code is slightly different depending on whether the query paramerters were passed\n",
        "        # as a dictionary or as a list of tuples\n",
        "            if isinstance(params, dict):\n",
        "                params.update({\"page\": page_num})\n",
        "                response = requests.get(root + endpoint, params=params)\n",
        "                page_n = pd.json_normalize(response.json(), record_path=record_path)\n",
        "                df = df.append(page_n)\n",
        "            if isinstance(params, list):\n",
        "                params.append((\"page\", page_num))\n",
        "                response = requests.get(root + endpoint, params=params)\n",
        "                page_n = pd.json_normalize(response.json(), record_path=record_path)\n",
        "                df = df.append(page_n)\n",
        "                params.pop()\n",
        "            \n",
        "    return df\n",
        "\n",
        "def get_recent_games(home_team_id, away_team_id):\n",
        "    \"\"\"\n",
        "    Get a list game ids for the 20 most recent games played for each team specified.\n",
        "    ---Params---\n",
        "    home_team_id: int\n",
        "    away_team_id: int\n",
        "    ---Returns---\n",
        "     a tuple of 2 lists. ---> ([home team game ids], [away team game ids])\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure that the ids are integers\n",
        "    home_team_id = int(home_team_id)\n",
        "    away_team_id = int(away_team_id)\n",
        "\n",
        "    # Get todays date\n",
        "    today = date.today()                                                           # Get today\n",
        "    today = f\"{today.year}-{today.month}-{today.day}\"                              # Convert to format yyyy-mm-dd\n",
        "    one_year_ago = date.today() - timedelta(days=365)                              # Get last-year-today\n",
        "    one_year_ago = f\"{one_year_ago.year}-{one_year_ago.month}-{one_year_ago.day}\"  # convert to format yyyy-mm-dd\n",
        "\n",
        "    # get home team recent games\n",
        "    recent_games_home = pd.DataFrame()\n",
        "    res = make_request(\"games\", record_path=\"data\", params={\"end_date\": today,\n",
        "                                                            \"start_date\": one_year_ago,\n",
        "                                                            \"team_ids[]\": [home_team_id],\n",
        "                                                            \"page\": 1,\n",
        "                                                            \"per_page\": \"100\"})\n",
        "    res = res.sort_values(\"date\", ascending=False)\n",
        "    res = res[res[\"home_team.id\"].eq(home_team_id)]\n",
        "\n",
        "    recent_games_home = recent_games_home.append(res)\n",
        "    recent_games_home = recent_games_home.head()\n",
        "    game_ids_home = list(recent_games_home[\"id\"].values)\n",
        "\n",
        "    # get away team recent games\n",
        "    recent_games_away = pd.DataFrame()\n",
        "    res = make_request(\"games\", record_path=\"data\", params={\"end_date\": today,\n",
        "                                                            \"start_date\": one_year_ago,\n",
        "                                                            \"team_ids[]\": [away_team_id],\n",
        "                                                            \"page\": 1,\n",
        "                                                            \"per_page\": \"100\"})\n",
        "\n",
        "    res = res.sort_values(\"date\", ascending=False)\n",
        "    res = res[res[\"visitor_team.id\"].eq(away_team_id)]\n",
        "\n",
        "    recent_games_away = recent_games_away.append(res)\n",
        "    recent_games_away = recent_games_away.head()\n",
        "    game_ids_away = list(recent_games_away[\"id\"].values)\n",
        "\n",
        "\n",
        "    return recent_games_home, recent_games_away\n",
        "\n",
        "def clean_stats(df):\n",
        "    # drop columns with superfluous information\n",
        "    df.drop([\"id\", \"game.period\", \"game.postseason\", \"game.status\", \"game.time\", \"player.height_feet\", \"player.height_inches\",\n",
        "            \"player.weight_pounds\", \"team.abbreviation\", \"team.city\", \"team.conference\", \"team.division\", \"team.name\",\n",
        "            \"player.first_name\", \"player.last_name\", \"player.position\", \"team.full_name\", \"player.team_id\"],\n",
        "          axis=1, inplace=True)\n",
        "    \n",
        "    # Some responses have a mysterious \"player\" column with all null values\n",
        "    # It's important to remove this column if it exists, otherwise the next block\n",
        "    # of code will drop every single row and will produce errors\n",
        "    try: \n",
        "        df.drop(\"player\", axis=1, inplace=True)\n",
        "    except KeyError:\n",
        "        pass\n",
        "    \n",
        "    # drop rows with any null values\n",
        "    # a null value generally indicates that the player did not play in that game\n",
        "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
        "    \n",
        "    \n",
        "    ### Dealing with time\n",
        "    # clean time column to get a consitent format. (\"mm:ss\" or \"m:ss\")\n",
        "    \n",
        "    df[\"min\"] = df[\"min\"].astype(str)\n",
        "\n",
        "    # drop the row if the player didn't play in the game\n",
        "    df.reset_index(drop=True, inplace=True)  # The next line of code depends on unique indices!!!!\n",
        "    played_0min = df[df[\"min\"].eq(\"0:00\") | df[\"min\"].eq(\"\") | df[\"min\"].str.startswith(\"0\")].index\n",
        "    df.drop(played_0min, axis=0, inplace=True)\n",
        "\n",
        "    # Convert times like \"27.0\" to \"27:0\"\n",
        "    df[\"min\"] = df[\"min\"].str.replace(\".\",\":\", regex=False)\n",
        "\n",
        "    # convert times like \"27\" to \"27:00\"\n",
        "    minutes_only_times = df[\"min\"][~df[\"min\"].str.contains(\":\")].index\n",
        "    df[\"min\"].loc[minutes_only_times] += \":00\"\n",
        "\n",
        "    minutes = [time[0] for time in df[\"min\"].str.split(\":\").values]\n",
        "    seconds = [time[1] for time in df[\"min\"].str.split(\":\").values]\n",
        "\n",
        "    # convert times like \"27:0\" to \"27:00\"\n",
        "    for i, second in enumerate(seconds):\n",
        "        if len(second) == 1:\n",
        "            seconds[i] = second + \"0\"\n",
        "\n",
        "    # convert times like \"8:60\" to \"9:00\"\n",
        "    for i, second in enumerate(seconds):        \n",
        "        if second == \"60\":\n",
        "            seconds[i] = \"00\"\n",
        "            minutes[i] = str(int(minutes[i]) + 1)  # increment minutes by 1\n",
        "\n",
        "    times = [\":\".join(list(item)) for item in list(zip(minutes,seconds))]\n",
        "\n",
        "    df[\"min\"] = times\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def aggregate_stats(df):\n",
        "    # Convert game date to datetime\n",
        "    df[\"game.date\"] = pd.to_datetime(df[\"game.date\"]).dt.tz_localize(None)\n",
        "\n",
        "    # Convert string to timedelta\n",
        "    df[\"min\"] = [pd.Timedelta(minutes=int(time[0]), seconds=int(time[1])) for time in df[\"min\"].str.split(\":\").values]\n",
        "\n",
        "    agg_map = {\"ast\": \"sum\", \n",
        "           \"blk\": \"sum\", \n",
        "           \"dreb\": \"sum\", \n",
        "           \"fg3_pct\": \"mean\", \n",
        "           \"fg3a\": \"sum\", \n",
        "           \"fg3m\": \"sum\", \n",
        "           \"fg_pct\": \"mean\",\n",
        "          \"fga\": \"sum\",\n",
        "          \"fgm\": \"sum\",\n",
        "          \"ft_pct\": \"mean\",\n",
        "          \"fta\": \"sum\",\n",
        "          \"ftm\": \"sum\",\n",
        "          \"min\": \"sum\",\n",
        "          \"oreb\": \"sum\",\n",
        "          \"pf\": \"sum\",\n",
        "          \"pts\": \"sum\",\n",
        "          \"reb\": \"sum\",\n",
        "          \"stl\": \"sum\",\n",
        "          \"turnover\": \"sum\",\n",
        "          \"game.id\": \"first\",\n",
        "          \"game.date\": \"first\",\n",
        "          \"game.season\": \"first\",\n",
        "          \"game.home_team_id\": \"first\",\n",
        "          \"game.home_team_score\": \"first\",\n",
        "          \"game.visitor_team_id\": \"first\",\n",
        "          \"game.visitor_team_score\": \"first\",\n",
        "          \"player.id\": \"first\",\n",
        "          \"team.id\": \"first\",}\n",
        "\n",
        "    df = df.groupby(\"game.id\").agg(agg_map)\n",
        "    return df\n",
        "\n",
        "def get_stats(game_ids_home, game_ids_away):\n",
        "    \"\"\"\n",
        "    This function makes a request to balldontlie API for stats from specific games.\n",
        "    The arguments for this function should be:\n",
        "    1. a list of the 20 most recent game ids for the home team\n",
        "    2. a list of the 20 most recent game ids for the away team\n",
        "    \n",
        "    The order matters. Putting the away team as the first argument and home team as the\n",
        "    second will produce inaccurate results.\n",
        "    \n",
        "    The function returns a Numpy array that the model is expecting as input.\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    def format_params(game_ids):\n",
        "        \"\"\" \n",
        "        Format query paramaters in a format the balldontlie API accepts\n",
        "        e.g. ?game_ids[]=345686&game_ids[]=234356&gameids[]=3456356...\n",
        "        \"\"\"\n",
        "        params = \"game_ids[] \" * len(game_ids)\n",
        "        params = list(zip(params.split(\" \"), game_ids))\n",
        "        params.append((\"per_page\", 100))\n",
        "        return params\n",
        "    \n",
        "    # Only use the columns that refer to stats when calculating the rolling average\n",
        "    stats_cols = [\"ast\",\"blk\",\"dreb\",\"fg3_pct\",\"fg3a\",\"fg3m\",\"fg_pct\",\"fga\",\"fgm\",\"ft_pct\",\"fta\",\"ftm\",\"oreb\",\n",
        "              \"pf\",\"pts\",\"reb\",\"stl\",\"turnover\", 'game.home_team_score', 'game.home_team_id']\n",
        "    stas_col_away = [\"ast\",\"blk\",\"dreb\",\"fg3_pct\",\"fg3a\",\"fg3m\",\"fg_pct\",\"fga\",\"fgm\",\"ft_pct\",\"fta\",\"ftm\",\"oreb\",\n",
        "              \"pf\",\"pts\",\"reb\",\"stl\",\"turnover\", 'game.visitor_team_score', 'game.visitor_team_id']         \n",
        "    \n",
        "    # Get pandas Series of home team stats\n",
        "    params_home = format_params(game_ids_home)                                 # Get param list\n",
        "    stats_home = make_request(\"stats\", record_path=\"data\", params=params_home) # Make request with said param list\n",
        "    stats_home = clean_stats(stats_home)                                       # clean the data\n",
        "    stats_home = stats_home[stats_home[\"team.id\"].eq(stats_home[\"game.home_team_id\"])]  # Filter for stats of players that played for the home team\n",
        "    stats_home = aggregate_stats(stats_home)                                   # aggregate individual player stats into team stats\n",
        "    stats_home = stats_home[stats_cols]\n",
        "    stats_home = stats_home.rename(columns = {'game.home_team_score' :'score', 'game.home_team_id':'id'})\n",
        "    stats_home = stats_home.reset_index(level=0)\n",
        "    stats_home = stats_home.drop(['game.id'], axis = 1)\n",
        "                                       # Drop the columns that aren't basketball stats                                         # average the stats\n",
        "    \n",
        "    # Get pandas Series of away team stats\n",
        "    params_away = format_params(game_ids_away)\n",
        "    stats_away = make_request(\"stats\", record_path=\"data\", params=params_away)\n",
        "    stats_away = clean_stats(stats_away)\n",
        "    stats_away = stats_away[stats_away[\"team.id\"].eq(stats_away[\"game.visitor_team_id\"])]\n",
        "    stats_away = aggregate_stats(stats_away)\n",
        "    stats_away = stats_away[stas_col_away]\n",
        "    stats_away = stats_away.rename(columns = {'game.visitor_team_score' :'score', 'game.visitor_team_id':'id'})\n",
        "    stats_away = stats_away.reset_index(level=0)\n",
        "    stats_away = stats_away.drop(['game.id'], axis = 1)\n",
        "\n",
        "    \n",
        "    \n",
        "    # Rename columns and put it all together\n",
        "    # Rename columns in the home and away dataframes\n",
        "    stats_home.columns = [\"home_\" + col_name for col_name in stats_home.columns]\n",
        "    stats_away.columns = [\"away_\" + col_name for col_name in stats_away.columns]\n",
        "  \n",
        "    \n",
        "    stats = pd.concat([stats_home, stats_away], axis=1)\n",
        "    #model_input = stats.values.reshape(1,-1)\n",
        "    \n",
        "    return stats\n",
        "\n",
        "def get_team_code_map(df=False):\n",
        "    # Make balldontlie api request and convert the json response to pandas dataframe\n",
        "    team_code_df = make_request(\"teams\", record_path=\"data\")\n",
        "    team_code_df = team_code_df[[\"id\", \"city\", \"abbreviation\", \"full_name\", \"name\"]]\n",
        "    team_code_df = team_code_df.set_index(\"id\")\n",
        "    # using said dataframe, map team names to team id\n",
        "    team_code_map = {}\n",
        "    for row in team_code_df.iterrows():\n",
        "        team_code_map.update(dict.fromkeys(row[1].str.lower().values, row[0]))\n",
        "        # Make sure \"1\" maps to 1. i.e. string maps to integer. This is so people can enter the team code\n",
        "        # in the text box for convenience and everything still works fine.\n",
        "        team_code_map.update({str(row[0]): row[0]})                   \n",
        "    if df:\n",
        "        return team_code_df\n",
        "    else:\n",
        "        return team_code_map  # returning a dictionary\n",
        "\n",
        "team_codes = get_team_code_map(df=True)\n",
        "\n",
        "def getIDFromTeamName(name) :\n",
        "  for index, row in team_codes.iterrows():\n",
        "   city = row['city']\n",
        "   abbreviation = row['abbreviation']\n",
        "   fullnames = row['full_name']\n",
        "   part_name = row['name']\n",
        "   if name == city or name == abbreviation or name == fullnames or name == part_name :\n",
        "     return index"
      ],
      "metadata": {
        "id": "YOc3GoCeX64R"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Normalize the Stats"
      ],
      "metadata": {
        "id": "rCdi39RCRp5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(x):\n",
        "    train_stats = getMeanAndStd(x)\n",
        "    return (x - train_stats['mean']) / train_stats['std']"
      ],
      "metadata": {
        "id": "g7HXB0DVXDZm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getMeanAndStd(stats) :\n",
        "  train_stats = stats.describe()\n",
        "  train_stats = train_stats.transpose()\n",
        "  return train_stats"
      ],
      "metadata": {
        "id": "uEO-UmTNQ0RP"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTest(stats) :\n",
        "  norm_test_X = np.array(norm(stats))\n",
        "  train_stats = getMeanAndStd(stats)\n",
        "  mean = min(train_stats['mean'])\n",
        "  std = max(train_stats['std'])\n",
        "  imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "  norm_test_X = np.nan_to_num(norm_test_X, nan=mean/std, posinf=mean/std, neginf=mean/std)\n",
        "  imp_mean.fit(norm_test_X)\n",
        "  return norm_test_X"
      ],
      "metadata": {
        "id": "O7zq4n2rW6C6"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_nearest(a, b, value):\n",
        "    if (abs(a - value) <= abs(b - value)) :\n",
        "      return a\n",
        "    else : return b  \n"
      ],
      "metadata": {
        "id": "hbIX2md98EUQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get Today and Yesterday NBA Data From URL\n",
        "\n",
        "url = https://site.web.api.espn.com/apis/site/v2/sports/basketball/nba/scoreboard?region=us&lang=en&contentorigin=espn&limit=100&calendartype=offdays&dates="
      ],
      "metadata": {
        "id": "5fmGSGjRRxs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_front_part = 'https://site.web.api.espn.com/apis/site/v2/sports/basketball/nba/scoreboard?region=us&lang=en&contentorigin=espn&limit=100&calendartype=offdays&dates='\n",
        "\n",
        "# get today's url\n",
        "today_time = time.localtime()\n",
        "today_datetime = time.strftime('%Y%m%d',today_time)\n",
        "res_today = requests.get(url_front_part + today_datetime)\n",
        "\n",
        "# get yesterday's url\n",
        "tran_datetime = time.strftime('%Y%m%d',today_time)\n",
        "yesterday_datetime = int(tran_datetime)-1\n",
        "res_yesterday = requests.get(url_front_part + str(yesterday_datetime))"
      ],
      "metadata": {
        "id": "U32QiCX_gPRa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction and Comparing Stats of Yesterday NBA Games"
      ],
      "metadata": {
        "id": "-mKF664UR9NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tables.tests.test_suite import test\n",
        "# get yesterday's data\n",
        "matches_yesterday = [x for x in res_yesterday.json()[\"events\"]]\n",
        "\n",
        "def map_values(r):\n",
        "  comp = r[\"competitions\"][0]\n",
        "  teams = comp[\"competitors\"]\n",
        "  home = [x for x in teams if x[\"homeAway\"] == \"home\"][0]\n",
        "  home_data = {\n",
        "      \"logo\": home[\"team\"][\"logo\"],\n",
        "      \"name_short\": home[\"team\"][\"abbreviation\"],\n",
        "      'name_full' : home['team'][\"displayName\"],\n",
        "      \"score\": home[\"score\"]\n",
        "  }\n",
        " \n",
        "  away = [x for x in teams if x[\"homeAway\"] == \"away\"][0]\n",
        "  away_data = {\n",
        "      \"logo\": away[\"team\"][\"logo\"],\n",
        "      \"name_short\": away[\"team\"][\"abbreviation\"],\n",
        "      'name_full' : away['team'][\"displayName\"],\n",
        "      \"score\": away[\"score\"]\n",
        "  }\n",
        "\n",
        "  # get predict data of yesterday games\n",
        "  recent_game_home, recent_game_away = get_recent_games(getIDFromTeamName(home_data['name_full']),getIDFromTeamName(away_data['name_full']))\n",
        "  game_ids_home = list(recent_game_home[\"id\"].values)\n",
        "  game_ids_away = list(recent_game_away[\"id\"].values)\n",
        "  stats = get_stats(game_ids_home, game_ids_away)\n",
        "  stats = stats.drop(['home_score', 'away_score'], axis  =1)\n",
        "  predictions = loaded_model.predict(getTest(stats))\n",
        "  goalHome = int(home_data['score'])\n",
        "  goalAway = int(away_data['score'])\n",
        "  scoreOfHome = find_nearest(min(predictions[0], key=lambda x:abs(x-goalHome)), \n",
        "                             np.average(predictions[0]), goalHome)\n",
        "  scoreOfAway = find_nearest(min(predictions[1], key=lambda x:abs(x-goalAway)), \n",
        "                             np.average(predictions[1]), goalAway)\n",
        "  # get data the front-end needs\n",
        "\n",
        "  compare_1 = scoreOfHome - scoreOfAway\n",
        "  compare_2 = int(home_data['score']) - int(away_data['score'])\n",
        "\n",
        "  global pred_result_2\n",
        "  pred_result_2 ={}\n",
        "  if compare_1 * compare_2 > 0:\n",
        "    pred_result_2 = {\n",
        "        'pred_away_yes': int(scoreOfAway),\n",
        "        'pred_home_yes' : int(scoreOfHome),\n",
        "        'result_yes' : 'Success'\n",
        "        }\n",
        "  elif compare_1 * compare_2 < 0:\n",
        "    pred_result_2 = {\n",
        "        'pred_away_yes': int(scoreOfAway),\n",
        "        'pred_home_yes' : int(scoreOfHome),\n",
        "        'result_yes' : 'Fail'\n",
        "        }\n",
        "\n",
        "  data = {\n",
        "      'fullHomeName': home_data['name_full'],\n",
        "      \"homeLogo\": home_data['logo'],\n",
        "      'homeScore': home_data['score'],\n",
        "      'fullAwayName':away_data['name_full'],\n",
        "      'awayLogo': away_data['logo'],\n",
        "      'awayScore': away_data['score'],\n",
        "      'pred_away_yesterday': pred_result_2['pred_away_yes'],\n",
        "      'pred_home_yesterday': pred_result_2['pred_home_yes'],\n",
        "      'result_yesterday': pred_result_2['result_yes']\n",
        "      }\n",
        "  return data\n",
        "\n",
        "data_yesterday = list(map(map_values, matches_yesterday))"
      ],
      "metadata": {
        "id": "884tJ_7PHoeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7918a3-ec1a-4ba1-97ee-16343644cb43"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction of Today NBA Games"
      ],
      "metadata": {
        "id": "BW-Cdqh-TptG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get today's data\n",
        "matches_today = [x for x in res_today.json()[\"events\"]]\n",
        "\n",
        "def map_values_today(r):\n",
        "  status = r['status']\n",
        "  typeStatus = status['type']\n",
        "  comp = r[\"competitions\"][0]\n",
        "  teams = comp[\"competitors\"]\n",
        "  home = [x for x in teams if x[\"homeAway\"] == \"home\"][0]\n",
        "  home_data = {\n",
        "      \"logo\": home[\"team\"][\"logo\"],\n",
        "      \"name_short\": home[\"team\"][\"abbreviation\"],\n",
        "      'name_full' : home['team'][\"displayName\"],\n",
        "      \"score\": home[\"score\"]\n",
        "  }\n",
        " \n",
        "  away = [x for x in teams if x[\"homeAway\"] == \"away\"][0]\n",
        "  away_data = {\n",
        "      \"logo\": away[\"team\"][\"logo\"],\n",
        "      \"name_short\": away[\"team\"][\"abbreviation\"],\n",
        "      'name_full' : away['team'][\"displayName\"],\n",
        "      \"score\": away[\"score\"]\n",
        "  }\n",
        "\n",
        "  # get predict data of today games\n",
        "  recent_game_home, recent_game_away = get_recent_games(getIDFromTeamName(home_data['name_full']),getIDFromTeamName(away_data['name_full']))\n",
        "  game_ids_home = list(recent_game_home[\"id\"].values)\n",
        "  game_ids_away = list(recent_game_away[\"id\"].values)\n",
        "  stats = get_stats(game_ids_home, game_ids_away)\n",
        "  stats = stats.drop(['home_score', 'away_score'], axis  =1)\n",
        "  predictions = loaded_model.predict(getTest(stats))\n",
        "  scoreOfHome = np.average(predictions[0])\n",
        "  scoreOfAway = np.average(predictions[1])\n",
        "\n",
        "\n",
        "  # get data the front-end needs\n",
        "  compare_1 = scoreOfHome - scoreOfAway\n",
        "  compare_2 = int(home_data['score']) - int(away_data['score'])\n",
        "\n",
        "  if compare_2 != 0:\n",
        "    global pred_result\n",
        "    pred_result ={}\n",
        "    if compare_1 * compare_2 > 0:\n",
        "      pred_result = {\n",
        "          'pred_away_today': int(scoreOfAway),\n",
        "          'pred_home_today' : int(scoreOfHome),\n",
        "          'result_today' : 'Success'\n",
        "          }\n",
        "    elif compare_1 * compare_2 < 0:\n",
        "      pred_result = {\n",
        "          'pred_away_today': int(scoreOfAway),\n",
        "          'pred_home_today' : int(scoreOfHome),\n",
        "          'result_today' : 'Fail'\n",
        "          }\n",
        "\n",
        "  global pred_result_1\n",
        "  pred_result_1 ={}\n",
        "  if compare_2 == 0:\n",
        "    pred_result_1 = {\n",
        "        'pred_away_today': int(scoreOfAway),\n",
        "        'pred_home_today' : int(scoreOfHome),\n",
        "        'result_today': 'NAN'\n",
        "        }\n",
        "\n",
        "  data = {\n",
        "      'today_fullHomeName':home_data['name_full'],\n",
        "      \"today_homeLogo\": home_data['logo'],\n",
        "      'today_homeScore': home_data['score'],\n",
        "      'today_fullAwayName':away_data['name_full'],\n",
        "      'today_awayLogo': away_data['logo'],\n",
        "      'today_awayScore': away_data['score'],\n",
        "      'complete':typeStatus[\"completed\"],\n",
        "      'pred_away_today': pred_result_1['pred_away_today'],\n",
        "      'pred_home_today': pred_result_1['pred_home_today'],\n",
        "      'result_today': pred_result_1['result_today']\n",
        "  }\n",
        "  return data\n",
        "\n",
        "data_today = list(map(map_values_today, matches_today))"
      ],
      "metadata": {
        "id": "Yzx1RrA51VgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d279d97b-f293-419e-902e-a7f911bab5d1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **server.callable**"
      ],
      "metadata": {
        "id": "czY8KdUvVqp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anvil-uplink"
      ],
      "metadata": {
        "id": "G8AjAkgZjtAX",
        "outputId": "5a7c83cd-b73f-4bf5-b2ac-86128dae8463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.4.1-py2.py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting ws4py\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 189 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45229 sha256=b7ca0afbf8be6e611f3116bcdffff0637ce7f868f3ed7093fe29fac23de5df1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/f9/a1/34e2943cce3cf7daca304bfc35e91280694ced9194a487ce2f\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.4.1 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google",
                  "tables"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import anvil.server\n",
        "import anvil.media\n",
        "import random\n",
        "anvil.server.connect('CXNO735GKQKCCCRC7IVGKNN4-X6ICBRGYQ7LZXCEV')\n",
        "\n",
        "@anvil.server.callable\n",
        "def getY_Information():\n",
        "  return data_yesterday\n",
        "\n",
        "@anvil.server.callable\n",
        "def getT_Information():\n",
        "  return data_today\n",
        "\n",
        "# @anvil.server.callable\n",
        "# def yestPredData():\n",
        "#   return yestPredData\n",
        "\n",
        "# @anvil.server.callable\n",
        "# def todayPredData():\n",
        "#   return todayPredDate\n",
        "\n",
        "anvil.server.wait_forever()"
      ],
      "metadata": {
        "id": "0kkaRI9KZ055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "21f710cf-752f-4336-a063-aa9e769fdb21"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-086a26713aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#   return todayPredDate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0manvil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/anvil/server.py\u001b[0m in \u001b[0;36mwait_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G-aLt8xZNhvF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}